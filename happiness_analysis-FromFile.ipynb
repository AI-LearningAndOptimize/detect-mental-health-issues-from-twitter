{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWITTER Happyness Analysys\n",
    "\n",
    "This notebook access directly saved twwets for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Connecting to Twitter\n",
    "\n",
    "Connecting to the twitter API using tweepy (twitter for python). Tweepy supports accessing Twitter via method, OAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.config.option_context at 0x127894048>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy, twitter_text\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import preprocessor as p\n",
    "import json\n",
    "from itertools import chain\n",
    "import objectpath\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "pd.set_option(\"display.max_colwidth\", 10000)\n",
    "pd.option_context('display.colheader_justify','left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetdf(json_txt):\n",
    "    ''' Read text file containing tweets in json format & create dataframe\n",
    "    Fields\n",
    "    id\n",
    "    full_text\n",
    "    \n",
    "    ''' \n",
    "    my_demo_list = []\n",
    "    with open(json_txt, encoding='utf-8') as json_file:  \n",
    "        all_data = json.load(json_file)\n",
    "        for each_dictionary in all_data:\n",
    "            tweet_id = each_dictionary['id']\n",
    "            full_text = each_dictionary['full_text']\n",
    "    #         favorite_count = each_dictionary['favorite_count']\n",
    "    #         retweet_count = each_dictionary['retweet_count']\n",
    "            created_at = each_dictionary['created_at']\n",
    "            my_demo_list.append({'tweet_id': str(tweet_id).strip(),\n",
    "                                 'full_text': str(full_text).strip().replace(r'\\u',''),\n",
    "    #                              'favorite_count': int(favorite_count),\n",
    "    #                              'retweet_count': int(retweet_count),\n",
    "                                 'created_at': created_at,\n",
    "                                })\n",
    "    tweet_df = pd.DataFrame(my_demo_list, columns = \n",
    "                              ['tweet_id', 'full_text', \n",
    "    #                            'favorite_count', 'retweet_count', \n",
    "                               'created_at'])\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = tweetdf('jobcentre.txt')\n",
    "tweet_df['full_text'] = tweet_df['full_text'].astype(str).str.lower()\n",
    "tweet_df = tweet_df[~tweet_df['full_text'].str.contains(\"brexit\")]\n",
    "tweet_df = tweet_df[~tweet_df['full_text'].str.contains(\"farage\")]\n",
    "no_queries = tweet_df.count()[1]\n",
    "no_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>happiness_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1109372701842513921</td>\n",
       "      <td>rt @davidbruce1982: half term at the new life centre. just some of our projects to make a note of.  #open #community #p3 #cab #jobcentre #y2026</td>\n",
       "      <td>Sat Mar 23 08:33:57 +0000 2019</td>\n",
       "      <td>102058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1109124922557763584</td>\n",
       "      <td>half term at the new life centre. just some of our projects to make a note of.  #open #community #p3 #cab #jobcentre #youth #spilsby https://t.co/29jqkavxhq</td>\n",
       "      <td>Fri Mar 22 16:09:22 +0000 2019</td>\n",
       "      <td>212135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1108880385344180224</td>\n",
       "      <td>forgot to tell u lot this but i went to jobcentre today n mi mate jake thoght it wuld b funnay to put fookin spice in mi folda with mi papers ! shat meself but thnx god i noticed d83dde21d83dde21d83dde21 rlly taking da piss watch out for dis guy if u kno him #jobcentre #takesdapiss #wtf</td>\n",
       "      <td>Thu Mar 21 23:57:40 +0000 2019</td>\n",
       "      <td>101917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1108847756918038528</td>\n",
       "      <td>\"we have engaged with social action but we haven't yet rediscovered a vision to build a church for the poor. this needs to change\" - a church for the poor https://t.co/jstq1spbtc #social action #poor #church #uk #universalcredit #dwp #jobcentre #mps #housing #homelessness https://t.co/yyjd65bwpf</td>\n",
       "      <td>Thu Mar 21 21:48:01 +0000 2019</td>\n",
       "      <td>194890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1108484383219036160</td>\n",
       "      <td>recieved this letter from #dwp regards to my #jobcentre interview on 15/3/19 for my claim on #universalcredit check the bottom who it's signed off by. they do not give a damn about people's lives or welfare. four months and counting. #isolationbooth #bulletproofglass https://t.co/jf7m3haq5z</td>\n",
       "      <td>Wed Mar 20 21:44:06 +0000 2019</td>\n",
       "      <td>174947.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  \\\n",
       "0  1109372701842513921   \n",
       "2  1109124922557763584   \n",
       "3  1108880385344180224   \n",
       "4  1108847756918038528   \n",
       "6  1108484383219036160   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                  full_text  \\\n",
       "0                                                                                                                                                           rt @davidbruce1982: half term at the new life centre. just some of our projects to make a note of.  #open #community #p3 #cab #jobcentre #y2026   \n",
       "2                                                                                                                                              half term at the new life centre. just some of our projects to make a note of.  #open #community #p3 #cab #jobcentre #youth #spilsby https://t.co/29jqkavxhq   \n",
       "3           forgot to tell u lot this but i went to jobcentre today n mi mate jake thoght it wuld b funnay to put fookin spice in mi folda with mi papers ! shat meself but thnx god i noticed d83dde21d83dde21d83dde21 rlly taking da piss watch out for dis guy if u kno him #jobcentre #takesdapiss #wtf   \n",
       "4  \"we have engaged with social action but we haven't yet rediscovered a vision to build a church for the poor. this needs to change\" - a church for the poor https://t.co/jstq1spbtc #social action #poor #church #uk #universalcredit #dwp #jobcentre #mps #housing #homelessness https://t.co/yyjd65bwpf   \n",
       "6       recieved this letter from #dwp regards to my #jobcentre interview on 15/3/19 for my claim on #universalcredit check the bottom who it's signed off by. they do not give a damn about people's lives or welfare. four months and counting. #isolationbooth #bulletproofglass https://t.co/jf7m3haq5z   \n",
       "\n",
       "                       created_at  happiness_rank  \n",
       "0  Sat Mar 23 08:33:57 +0000 2019        102058.0  \n",
       "2  Fri Mar 22 16:09:22 +0000 2019        212135.0  \n",
       "3  Thu Mar 21 23:57:40 +0000 2019        101917.0  \n",
       "4  Thu Mar 21 21:48:01 +0000 2019        194890.0  \n",
       "6  Wed Mar 20 21:44:06 +0000 2019        174947.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating  polarity scores\n",
    "To calculate Polarity, Vader Algorithm is used. The Vader Algorithm outputs sentiment scores to 4 classes of sentiments:\n",
    "\n",
    "• neg   Negative \n",
    "\n",
    "• pos   Positive\n",
    "\n",
    "• neu   Neutral\n",
    "\n",
    "• Compound : Compound \n",
    "Using these sentiment scores we can easily calculate percentage classification of Sentiment on tweets fetched. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(part,whole):\n",
    "    return(100* float(part)/float(whole))\n",
    "\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# for i in list1:\n",
    "for i in tweet_df['full_text']:\n",
    "    sps = sid.polarity_scores(i)\n",
    "    negative +=sps['neg']\n",
    "    neutral +=sps['neu']\n",
    "    positive +=sps['pos']\n",
    "  \n",
    "positive = round(percent(positive,no_queries),2)\n",
    "negative = round(percent(negative,no_queries),2)\n",
    "neutral = round(percent(neutral,no_queries),2)\n",
    "\n",
    "print(positive,'%'+' positive')\n",
    "print(negative,'%'+' negative')\n",
    "print(neutral,'%'+' neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visual Interpretation of Analysis \n",
    "\n",
    "To visually interpret our sentiment analysis, we will further use Matplotlib library of Python for plotting a Pie Chart, that diagrammatically shows people opinion on the searched query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Positive ['+str(positive)+'%]','Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
    "sizes = [positive,neutral,negative]\n",
    "colors = ['green','blue','red']\n",
    "patches,texts  =plt.pie(sizes,colors = colors,startangle=90)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.legend(patches,labels,loc='best')\n",
    "plt.title('Analysis for jobcentre on '+str(no_queries)+' tweets')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dataset\n",
    "\n",
    "Dataset twitter_samples used here contain 3 files : \n",
    "\n",
    "1 negative_tweets.json (Contain sample negative tweets)\n",
    "\n",
    "2 positive_tweets,json  (Contain sample positive tweets) \n",
    "\n",
    "3 tweets.20150430-223406.json (Contain sample neutral tweets) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negtweets = twitter_samples.strings('negative_tweets.json')\n",
    "postweets = twitter_samples.strings('positive_tweets.json')\n",
    "negtweets = twitter_samples.strings('negative_tweets.json')\n",
    "postweets = twitter_samples.strings('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training classifier object with dataset\n",
    "\n",
    "In order to classify tweets on the basis of sentiments, we need to train a classifier using Machine learning methods. Some of popular methods are Support Vector Machines (SVM), Naive Bayes Classifier etc. Naïve Bayes Classifier being the most convenient one, is used here to train  twitter_samples (nltk corpora) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word,True) for word in words])\n",
    "\n",
    "negfeats = [(word_feats(nltk.word_tokenize(p.clean(i))),'neg') for i in negtweets]\n",
    "posfeats = [(word_feats(nltk.word_tokenize(p.clean(i))),'pos') for i in postweets]\n",
    "#print(negfeats)\n",
    "\n",
    "\n",
    "#neg_t = word_feats(negfeats,neg_words)\n",
    "#pos_t = word_feats(posfeats,pos_words)\n",
    "negcutoff = int(len(negfeats)*1/2)\n",
    "poscutoff = int(len(posfeats)*1/2)\n",
    "trainfeats = negfeats[:negcutoff]+posfeats[:poscutoff]\n",
    "testfeats = posfeats[negcutoff:]+posfeats[poscutoff:]\n",
    "\n",
    "print(\"Train on %d instances, test on %d instances\"%(len(trainfeats),len(testfeats)))\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALCULATING ACCURACY OF CLASSIFIER OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",nltk.classify.util.accuracy(classifier,testfeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 6666 instances , test on 3334     instances\n",
    "Accuracy: 0.73125374925015\n",
    "\n",
    "Train on 7500 instances , test on 2500     instances\n",
    "Accuracy: 0.7208\n",
    "\n",
    "Here we saw that with increase in training examples accuracy decreases. It is clear case of High Bias. So to improve accuracywe can do following:\n",
    "\n",
    "1. Decrease Training Examples .\n",
    "2. Switching to some other ML model for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTING SENTIMENT FROM TWEETS FETCHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tweet_df['full_text'][:20]:\n",
    "    test_tweet = word_feats(i)\n",
    "    print(i+\"::\"+classifier.classify(test_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happiness Analysis\n",
    "\n",
    "Using the labMIT Happness index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_average</th>\n",
       "      <th>happiness_standard_deviation</th>\n",
       "      <th>twitter_rank</th>\n",
       "      <th>google_rank</th>\n",
       "      <th>nyt_rank</th>\n",
       "      <th>lyrics_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>laughter</td>\n",
       "      <td>1</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>3600</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiness</td>\n",
       "      <td>2</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>1853</td>\n",
       "      <td>2458</td>\n",
       "      <td>--</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.1082</td>\n",
       "      <td>25</td>\n",
       "      <td>317</td>\n",
       "      <td>328</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>4</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>65</td>\n",
       "      <td>1372</td>\n",
       "      <td>1313</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laughed</td>\n",
       "      <td>5</td>\n",
       "      <td>8.26</td>\n",
       "      <td>1.1572</td>\n",
       "      <td>3334</td>\n",
       "      <td>3542</td>\n",
       "      <td>--</td>\n",
       "      <td>2332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  happiness_rank  happiness_average  happiness_standard_deviation  \\\n",
       "0   laughter               1               8.50                        0.9313   \n",
       "1  happiness               2               8.44                        0.9723   \n",
       "2       love               3               8.42                        1.1082   \n",
       "3      happy               4               8.30                        0.9949   \n",
       "4    laughed               5               8.26                        1.1572   \n",
       "\n",
       "  twitter_rank google_rank nyt_rank lyrics_rank  \n",
       "0         3600          --       --        1728  \n",
       "1         1853        2458       --        1230  \n",
       "2           25         317      328          23  \n",
       "3           65        1372     1313         375  \n",
       "4         3334        3542       --        2332  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labMIT = pd.read_csv(\"labMIT-1.0-mod.txt\",  delim_whitespace=True)\n",
    "labMIT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labMIT.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n",
      "1038\n"
     ]
    }
   ],
   "source": [
    "happiness_rank = []\n",
    "for i in tweet_df['full_text']:\n",
    "    tokens = nltk.word_tokenize(i)\n",
    "    cnt = 0\n",
    "    for j in labMIT.index:\n",
    "        val = labMIT.at[j,'word']\n",
    "        if (val in tokens):\n",
    "            cnt = cnt + labMIT.at[ j,'happiness_rank']\n",
    "\n",
    "    happiness_rank.append(cnt) \n",
    "print(len(happiness_rank))\n",
    "print(len(tweet_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1038, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['happiness_rank'] = pd.Series(happiness_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "twdf = tweet_df.dropna(subset=['happiness_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>happiness_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>rt @respectisvital: d83ddea8new - #gogglebox pushes dwp propaganda in planned broadcast.\\n\\ntonight saw @channel4 sell their soul after they aired a2026</td>\n",
       "      <td>11581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>rt @mrtopple: umm, #isitok that while nearly 4m people have signed the #revokearticle50petition only 7k have signed one calling for an inqu2026</td>\n",
       "      <td>11941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>rt @hovellinghermit: how can #disabled people have faith in a system where paperwork submitted by the #dwp in a benefits appeal tribunal ca2026</td>\n",
       "      <td>13268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>come along to our stand at gloucester job centre today and discuss your future employment - rich &amp;amp; shell are waiting to speak to you until noon today d83ddc4dd83ddc4d\\n#gloshour #jobcentre #gloucester  @jcpingloucester https://t.co/ojczegawue</td>\n",
       "      <td>13759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>rt @mrtopple: umm, #isitok that while nearly 4m people have signed the #revokearticle50petition only 7k have signed one calling for an inqu2026</td>\n",
       "      <td>17055.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                   full_text  \\\n",
       "554                                                                                                 rt @respectisvital: d83ddea8new - #gogglebox pushes dwp propaganda in planned broadcast.\\n\\ntonight saw @channel4 sell their soul after they aired a2026   \n",
       "78                                                                                                           rt @mrtopple: umm, #isitok that while nearly 4m people have signed the #revokearticle50petition only 7k have signed one calling for an inqu2026   \n",
       "1029                                                                                                         rt @hovellinghermit: how can #disabled people have faith in a system where paperwork submitted by the #dwp in a benefits appeal tribunal ca2026   \n",
       "12    come along to our stand at gloucester job centre today and discuss your future employment - rich &amp; shell are waiting to speak to you until noon today d83ddc4dd83ddc4d\\n#gloshour #jobcentre #gloucester  @jcpingloucester https://t.co/ojczegawue   \n",
       "488                                                                                                          rt @mrtopple: umm, #isitok that while nearly 4m people have signed the #revokearticle50petition only 7k have signed one calling for an inqu2026   \n",
       "\n",
       "      happiness_rank  \n",
       "554          11581.0  \n",
       "78           11941.0  \n",
       "1029         13268.0  \n",
       "12           13759.0  \n",
       "488          17055.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twdf = twdf.sort_values('happiness_rank')\n",
    "twdf[['full_text','happiness_rank'] ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>happiness_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>rt @jordaniel_rb: @hovellinghermit then whomever wrote that particular statement of the apellant, should be sought and employment terminate2026</td>\n",
       "      <td>180599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>rt @hovellinghermit: how can #disabled people have faith in a system where paperwork submitted by the #dwp in a benefits appeal tribunal ca2026</td>\n",
       "      <td>185263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>rt @mrtopple: umm, #isitok that while nearly 4m people have signed the #revokearticle50petition only 7k have signed one calling for an inqu2026</td>\n",
       "      <td>187752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>dwp document refers to benefit claimant as 'lying bitch'\\n\\nhttps://t.co/ejwh1srpyl\\nthis is the reason so many hate the #dwp and their bullying of #vulnerablepeople \\n#dwpcrimes\\n@amberruddhr</td>\n",
       "      <td>192979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"we have engaged with social action but we haven't yet rediscovered a vision to build a church for the poor. this needs to change\" - a church for the poor https://t.co/jstq1spbtc #social action #poor #church #uk #universalcredit #dwp #jobcentre #mps #housing #homelessness https://t.co/yyjd65bwpf</td>\n",
       "      <td>194890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>rt @mojos55: #dwp unqualified assessors.. having power to over ride our doctors &amp;amp; consultants diagnosis ! if i were the patient doctor or c2026</td>\n",
       "      <td>196949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>@raging545 @mrtopple @pressjournal stick to the argument.\\n\\nwhat's more important. \\n\\nthe #eu or #dwp killing 30 people a day?</td>\n",
       "      <td>203845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half term at the new life centre. just some of our projects to make a note of.  #open #community #p3 #cab #jobcentre #youth #spilsby https://t.co/29jqkavxhq</td>\n",
       "      <td>212135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>rt @johnpringdns: the disabled daughter of a woman who took her own life after losing her disability benefits has explained why she believe2026</td>\n",
       "      <td>214371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>banned from the #jobcentre - after 'losing the plot' over months of trying to get #universalcredit #hostileenviroment #homelessness https://t.co/gprpfysg2w</td>\n",
       "      <td>228860.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                     full_text  \\\n",
       "1016                                                                                                                                                           rt @jordaniel_rb: @hovellinghermit then whomever wrote that particular statement of the apellant, should be sought and employment terminate2026   \n",
       "1024                                                                                                                                                           rt @hovellinghermit: how can #disabled people have faith in a system where paperwork submitted by the #dwp in a benefits appeal tribunal ca2026   \n",
       "744                                                                                                                                                            rt @mrtopple: umm, #isitok that while nearly 4m people have signed the #revokearticle50petition only 7k have signed one calling for an inqu2026   \n",
       "1011                                                                                                          dwp document refers to benefit claimant as 'lying bitch'\\n\\nhttps://t.co/ejwh1srpyl\\nthis is the reason so many hate the #dwp and their bullying of #vulnerablepeople \\n#dwpcrimes\\n@amberruddhr   \n",
       "4     \"we have engaged with social action but we haven't yet rediscovered a vision to build a church for the poor. this needs to change\" - a church for the poor https://t.co/jstq1spbtc #social action #poor #church #uk #universalcredit #dwp #jobcentre #mps #housing #homelessness https://t.co/yyjd65bwpf   \n",
       "362                                                                                                                                                        rt @mojos55: #dwp unqualified assessors.. having power to over ride our doctors &amp; consultants diagnosis ! if i were the patient doctor or c2026   \n",
       "785                                                                                                                                                                           @raging545 @mrtopple @pressjournal stick to the argument.\\n\\nwhat's more important. \\n\\nthe #eu or #dwp killing 30 people a day?   \n",
       "2                                                                                                                                                 half term at the new life centre. just some of our projects to make a note of.  #open #community #p3 #cab #jobcentre #youth #spilsby https://t.co/29jqkavxhq   \n",
       "916                                                                                                                                                            rt @johnpringdns: the disabled daughter of a woman who took her own life after losing her disability benefits has explained why she believe2026   \n",
       "25                                                                                                                                                 banned from the #jobcentre - after 'losing the plot' over months of trying to get #universalcredit #hostileenviroment #homelessness https://t.co/gprpfysg2w   \n",
       "\n",
       "      happiness_rank  \n",
       "1016        180599.0  \n",
       "1024        185263.0  \n",
       "744         187752.0  \n",
       "1011        192979.0  \n",
       "4           194890.0  \n",
       "362         196949.0  \n",
       "785         203845.0  \n",
       "2           212135.0  \n",
       "916         214371.0  \n",
       "25          228860.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twdf[['full_text', 'happiness_rank']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\uword'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = r'\\uword'\n",
    "string.replace(r'\\u','')\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xyz …'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'xyz \\u2026'\n",
    "string.replace(r'\\u2026','')\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\uword'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = r'\\uword'\n",
    "string.replace(r'\\u', '')\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
